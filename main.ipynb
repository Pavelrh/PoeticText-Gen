{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    " \n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import keras.utils\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "# we increase peformance  by using only lowercase\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'k': 23, 'l': 24, 'm': 25, 'n': 26, 'o': 27, 'p': 28, 'q': 29, 'r': 30, 's': 31, 't': 32, 'u': 33, 'v': 34, 'w': 35, 'x': 36, 'y': 37, 'z': 38}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'a', 14: 'b', 15: 'c', 16: 'd', 17: 'e', 18: 'f', 19: 'g', 20: 'h', 21: 'i', 22: 'j', 23: 'k', 24: 'l', 25: 'm', 26: 'n', 27: 'o', 28: 'p', 29: 'q', 30: 'r', 31: 's', 32: 't', 33: 'u', 34: 'v', 35: 'w', 36: 'x', 37: 'y', 38: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# we only use this much because we dont have the necessary computational power to train the entire dataset\n",
    "\n",
    "\n",
    "# sort basically sorts it and set basically just saves it as unique text.\n",
    "characters = sorted(set(text))\n",
    "\n",
    "# enumerate iterates over a list and returns the list item with an index for example -> 1, fruit\n",
    "char_to_index = dict((c,i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i,c) for i, c in enumerate(characters)) \n",
    "\n",
    "print(char_to_index)\n",
    "print(index_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "step_size = 3\n",
    "\n",
    "# basically sentences and next_characters are the X & Y\n",
    "# which means sentences are the Input data and the next_characters are the target data\n",
    "\n",
    "sentences = []\n",
    "next_characters = []\n",
    "\n",
    "for i in range(0, len(text) - seq_length, step_size):\n",
    "    sentences.append(text[i:i+seq_length])\n",
    "    next_characters.append(text[i+seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False,  True, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False,  True, False, ..., False, False, False]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False,  True, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False,  True, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros((len(sentences), seq_length, len(characters)), dtype=bool)\n",
    "Y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
    "\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        X[i, t, char_to_index[character]] = 1\n",
    "    Y[i, char_to_index[next_characters[i]]] = 1 \n",
    "\n",
    "X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_length, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 55ms/step - loss: 1.3749\n",
      "Epoch 2/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 59ms/step - loss: 1.3650\n",
      "Epoch 3/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 55ms/step - loss: 1.3502\n",
      "Epoch 4/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 54ms/step - loss: 1.3462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16ea4ff36d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "model.fit(X, Y, batch_size=256, epochs=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('textgen-s.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('textgen-s.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)/temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds/ np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - seq_length - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + seq_length]\n",
    "    generated += sentence\n",
    "\n",
    "    for i in range(length):\n",
    "        x = np.zeros((1, seq_length, len(characters)))\n",
    "        for t, character in enumerate(sentence):\n",
    "            x[0, t, char_to_index[character]] = 1\n",
    "\n",
    "        predictions = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(predictions, temperature)\n",
    "        next_character = index_to_char[next_index] \n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----300,0.2----\n",
      "hard ii:\n",
      "twice for one step i'll groan, the state,\n",
      "and the throng the prince that the world,\n",
      "the state of the state of the stander than it is a prison\n",
      "which i have the state to the marries and the sea\n",
      "the world as i would see the world the man that i have the brother that i see\n",
      "the brother will not stay the streep to see\n",
      "the seas, and mar\n",
      "----500,0.2----\n",
      "ome.\n",
      "here comes his mother.\n",
      "\n",
      "sicinius:\n",
      "let me some promised the prince of the world.\n",
      "\n",
      "provost:\n",
      "i will be some more as offence the seat,\n",
      "and the world the state of the seather souls,\n",
      "that i see the brother and some son, and the marries,\n",
      "the cause of the world so many the world.\n",
      "\n",
      "brutus:\n",
      "what shall she were the seas,\n",
      "and which i have done the stander with the prince:\n",
      "i have the brother than the man the greaterous son,\n",
      "and the dear the staught of the seather,\n",
      "but the stander than the world in the world,\n",
      "and the man that i have the world \n",
      "----600,0.2----\n",
      "d and would have married her perforce\n",
      "to see the state of the king and the fortune\n",
      "in the promised and married the seat,\n",
      "and the world in the compassed strength,\n",
      "so i have the state of the string that the world,\n",
      "the strike of the man shall be stands the see,\n",
      "and the world the brother and the dearly son,\n",
      "and what i see the string the fair with me\n",
      "that which i will be married the string to him.\n",
      "\n",
      "provost:\n",
      "what shall i come to the land,\n",
      "the seas, i will be married the lands,\n",
      "the world in the lady are some son and soul.\n",
      "\n",
      "gloucester:\n",
      "i would be the brother to the fair of the rest\n",
      "than the world than the state stands the sea\n",
      "that stay the \n"
     ]
    }
   ],
   "source": [
    "print('----300,0.2----')\n",
    "print(generate_text(300, 0.2))\n",
    "print('----500,0.2----')\n",
    "print(generate_text(500, 0.2))\n",
    "print('----600,0.2----')\n",
    "print(generate_text(600, 0.2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
